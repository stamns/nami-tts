# ä½¿ç”¨ç¤ºä¾‹ - NanoAI TTS å®æˆ˜æ•™ç¨‹

[![è¿”å› README](https://img.shields.io/badge/è¿”å›-README--CN-blue?style=flat-square)](./README-CN.md)
[![éƒ¨ç½²æŒ‡å—](https://img.shields.io/badge/éƒ¨ç½²-DEPLOYMENT--CN-green?style=flat-square)](./DEPLOYMENT-CN.md)
[![FAQ](https://img.shields.io/badge/å¸¸è§é—®é¢˜-FAQ--CN-orange?style=flat-square)](./FAQ-CN.md)

æœ¬æ–‡æ¡£é€šè¿‡å¤šä¸ªå®é™…ä½¿ç”¨åœºæ™¯ï¼Œæ¼”ç¤ºå¦‚ä½•æœ‰æ•ˆä½¿ç”¨ NanoAI TTS æœåŠ¡ã€‚

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿå¼€å§‹](#å¿«é€Ÿå¼€å§‹)
- [Web ç•Œé¢ä½¿ç”¨](#web-ç•Œé¢ä½¿ç”¨)
- [Python é›†æˆ](#python-é›†æˆ)
- [JavaScript é›†æˆ](#javascript-é›†æˆ)
- [å®æˆ˜åœºæ™¯](#å®æˆ˜åœºæ™¯)
- [æ‰¹é‡å¤„ç†](#æ‰¹é‡å¤„ç†)
- [é«˜çº§æŠ€å·§](#é«˜çº§æŠ€å·§)

## ğŸš€ å¿«é€Ÿå¼€å§‹

### æœ€ç®€å•çš„ç”¨æ³•

```python
import requests

# ç”Ÿæˆä¸€å¥è¯çš„éŸ³é¢‘
response = requests.post('http://localhost:5001/v1/audio/speech', json={
    'input': 'ä½ å¥½ï¼Œä¸–ç•Œ',
    'model': 'DeepSeek',
})

# ä¿å­˜ä¸º MP3 æ–‡ä»¶
with open('hello.mp3', 'wb') as f:
    f.write(response.content)
```

### Web ç•Œé¢ä½¿ç”¨

1. æ‰“å¼€ http://localhost:5001
2. åœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬
3. é€‰æ‹©è¯­è¨€å’Œæ€§åˆ«
4. ç‚¹å‡»"ç”ŸæˆéŸ³é¢‘"æŒ‰é’®
5. ç‚¹å‡»æ’­æ”¾æˆ–ä¸‹è½½

## ğŸŒ Web ç•Œé¢ä½¿ç”¨

### åŸºæœ¬æ“ä½œ

#### æ­¥éª¤ 1ï¼šè¾“å…¥æ–‡æœ¬

åœ¨ä¸»é¡µçš„æ–‡æœ¬æ¡†ä¸­è¾“å…¥ä½ è¦è½¬æ¢çš„æ–‡æœ¬ã€‚æœ€ç®€å•çš„ä¾‹å­ï¼š

```
ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ NanoAI TTS æœåŠ¡ã€‚
```

#### æ­¥éª¤ 2ï¼šè°ƒæ•´å‚æ•°

ä½¿ç”¨å³ä¾§çš„å‚æ•°é¢æ¿ï¼š

- **è¯­è¨€**: é€‰æ‹©"ç®€ä½“ä¸­æ–‡"
- **æ€§åˆ«**: é€‰æ‹©"å¥³"æˆ–"ç”·"
- **é€Ÿåº¦**: æ‹–åŠ¨æ»‘æ¡è°ƒæ•´ï¼ˆ1.0 ä¸ºæ­£å¸¸é€Ÿåº¦ï¼‰
- **éŸ³è°ƒ**: è°ƒæ•´å£°éŸ³é«˜ä½
- **éŸ³é‡**: è°ƒæ•´éŸ³é¢‘å¤§å°

#### æ­¥éª¤ 3ï¼šç”Ÿæˆå’Œä¸‹è½½

ç‚¹å‡»"ç”ŸæˆéŸ³é¢‘"æŒ‰é’®ï¼Œç­‰å¾…å‡ ç§’é’Ÿåï¼š

- åœ¨æ’­æ”¾å™¨ä¸­æ’­æ”¾ç”Ÿæˆçš„éŸ³é¢‘
- ç‚¹å‡»"ä¸‹è½½"æŒ‰é’®ä¸‹è½½ MP3 æ–‡ä»¶
- ç‚¹å‡»"å¤åˆ¶é“¾æ¥"å¤åˆ¶åˆ†äº«é“¾æ¥

### é«˜çº§åŠŸèƒ½

#### æ‰¹é‡è½¬æ¢

å¯¹äºå¤šä¸ªå¥å­ï¼Œå¯ä»¥ï¼š

1. æ¯ä¸ªå¥å­ç”Ÿæˆä¸€ä¸ªéŸ³é¢‘
2. ä½¿ç”¨éŸ³é¢‘ç¼–è¾‘è½¯ä»¶æ‹¼æ¥
3. æˆ–è€…å°†å¤šä¸ªå¥å­ä¸€èµ·è¾“å…¥ï¼ˆç³»ç»Ÿä¼šè‡ªåŠ¨å¤„ç†ï¼‰

#### å¯¹æ¯”ä¸åŒå‚æ•°

ç”Ÿæˆç›¸åŒæ–‡æœ¬çš„ä¸åŒç‰ˆæœ¬ï¼š

- **æ­£å¸¸é€Ÿåº¦**: speed = 1.0
- **å¿«é€Ÿ**: speed = 1.5ï¼ˆé€‚åˆå¿«é€Ÿæµè§ˆï¼‰
- **æ…¢é€Ÿ**: speed = 0.75ï¼ˆé€‚åˆå­¦ä¹ ï¼‰

## ğŸ Python é›†æˆ

### å®‰è£…ä¾èµ–

```bash
pip install requests python-dotenv
```

### åŸºç¡€ç¤ºä¾‹

#### ä¾‹ 1ï¼šç®€å•çš„æ–‡æœ¬è½¬è¯­éŸ³

```python
import requests
import os
from dotenv import load_dotenv

load_dotenv()

# æœåŠ¡ URL
BASE_URL = os.getenv('TTS_API_URL', 'http://localhost:5001')

# å‘é€è¯·æ±‚
response = requests.post(f'{BASE_URL}/v1/audio/speech', json={
    'input': 'è¿™æ˜¯ä¸€ä¸ªæµ‹è¯•å¥å­ã€‚',
    'model': 'DeepSeek',
    'language': 'zh-CN',
})

# ä¿å­˜æ–‡ä»¶
if response.status_code == 200:
    with open('test.mp3', 'wb') as f:
        f.write(response.content)
    print("âœ“ éŸ³é¢‘ç”ŸæˆæˆåŠŸï¼štest.mp3")
else:
    print(f"âœ— é”™è¯¯: {response.status_code}")
    print(response.text)
```

#### ä¾‹ 2ï¼šç”Ÿæˆæœ‰å£°ä¹¦

```python
import requests
import os

# å°è¯´æ–‡æœ¬ï¼ˆæ¥è‡ªæ–‡ä»¶ï¼‰
with open('novel.txt', 'r', encoding='utf-8') as f:
    novel_text = f.read()

# API å‚æ•°
params = {
    'input': novel_text,
    'model': 'DeepSeek',
    'language': 'zh-CN',
    'gender': 'female',
    'speed': 1.0,
}

# ç”ŸæˆéŸ³é¢‘
response = requests.post('http://localhost:5001/v1/audio/speech', json=params)

if response.status_code == 200:
    # é•¿æ–‡æœ¬ä¼šè¿”å› ZIP æˆ– M3U8
    content_type = response.headers.get('content-type', '')
    
    if 'zip' in content_type:
        # ä¿å­˜ä¸º ZIP
        with open('audiobook.zip', 'wb') as f:
            f.write(response.content)
        print("âœ“ æœ‰å£°ä¹¦ç”Ÿæˆå®Œæ¯•ï¼šaudiobook.zip")
    else:
        # ä¿å­˜ä¸ºå•ä¸ª MP3
        with open('audiobook.mp3', 'wb') as f:
            f.write(response.content)
        print("âœ“ æœ‰å£°ä¹¦ç”Ÿæˆå®Œæ¯•ï¼šaudiobook.mp3")
```

#### ä¾‹ 3ï¼šå¤šè¯­è¨€æ”¯æŒ

```python
import requests

texts = {
    'zh-CN': 'ä½ å¥½ï¼Œä¸–ç•Œ',
    'en-US': 'Hello, world',
    'ja-JP': 'ã“ã‚“ã«ã¡ã¯ã€ä¸–ç•Œ',
    'ko-KR': 'ì•ˆë…•í•˜ì„¸ìš”, ì„¸ìƒ',
}

for lang_code, text in texts.items():
    response = requests.post('http://localhost:5001/v1/audio/speech', json={
        'input': text,
        'language': lang_code,
        'model': 'DeepSeek',
    })
    
    if response.status_code == 200:
        filename = f'audio_{lang_code}.mp3'
        with open(filename, 'wb') as f:
            f.write(response.content)
        print(f"âœ“ {lang_code}: {filename}")
```

#### ä¾‹ 4ï¼šå‚æ•°è°ƒä¼˜

```python
import requests

text = "è¿™æ˜¯ä¸€ä¸ªéœ€è¦ä¸åŒå‚æ•°é…ç½®çš„ç¤ºä¾‹æ–‡æœ¬ã€‚"

# å®šä¹‰ä¸åŒçš„é…ç½®
configs = {
    'fast': {'speed': 1.5, 'pitch': 1.0},
    'normal': {'speed': 1.0, 'pitch': 1.0},
    'slow': {'speed': 0.75, 'pitch': 1.0},
    'high_pitch': {'speed': 1.0, 'pitch': 1.5},
    'low_pitch': {'speed': 1.0, 'pitch': 0.75},
}

for config_name, params in configs.items():
    response = requests.post('http://localhost:5001/v1/audio/speech', json={
        'input': text,
        'model': 'DeepSeek',
        **params
    })
    
    if response.status_code == 200:
        filename = f'audio_{config_name}.mp3'
        with open(filename, 'wb') as f:
            f.write(response.content)
        print(f"âœ“ {config_name}: {filename}")
```

#### ä¾‹ 5ï¼šé”™è¯¯å¤„ç†å’Œé‡è¯•

```python
import requests
import time

def generate_speech_with_retry(text, max_retries=3):
    """å¸¦é‡è¯•çš„éŸ³é¢‘ç”Ÿæˆå‡½æ•°"""
    
    for attempt in range(max_retries):
        try:
            response = requests.post(
                'http://localhost:5001/v1/audio/speech',
                json={'input': text, 'model': 'DeepSeek'},
                timeout=30
            )
            
            if response.status_code == 200:
                return response.content
            
            elif response.status_code >= 500:
                # æœåŠ¡å™¨é”™è¯¯ï¼Œé‡è¯•
                print(f"æœåŠ¡å™¨é”™è¯¯ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
                time.sleep(2 ** attempt)  # æŒ‡æ•°é€€é¿
            
            else:
                # å®¢æˆ·ç«¯é”™è¯¯ï¼Œä¸é‡è¯•
                print(f"å®¢æˆ·ç«¯é”™è¯¯: {response.status_code}")
                print(response.json())
                return None
        
        except requests.Timeout:
            print(f"è¯·æ±‚è¶…æ—¶ï¼Œæ­£åœ¨é‡è¯•... (å°è¯• {attempt + 1}/{max_retries})")
            time.sleep(2 ** attempt)
        
        except Exception as e:
            print(f"é”™è¯¯: {e}")
            return None
    
    print("âœ— æ‰€æœ‰é‡è¯•éƒ½å¤±è´¥")
    return None

# ä½¿ç”¨
audio_data = generate_speech_with_retry("æµ‹è¯•æ–‡æœ¬")
if audio_data:
    with open('output.mp3', 'wb') as f:
        f.write(audio_data)
```

### é«˜çº§ Python ç¤ºä¾‹

#### ä¾‹ 6ï¼šæ„å»º TTS å®¢æˆ·ç«¯ç±»

```python
import requests
import os
from dotenv import load_dotenv
from typing import Optional, Dict, Any
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class NanoAITTSClient:
    """NanoAI TTS å®¢æˆ·ç«¯"""
    
    def __init__(self, api_url: str = 'http://localhost:5001'):
        self.api_url = api_url
        self.base_params = {
            'model': 'DeepSeek',
            'language': 'zh-CN',
            'gender': 'female',
        }
    
    def set_default_model(self, model: str):
        """è®¾ç½®é»˜è®¤æ¨¡å‹"""
        self.base_params['model'] = model
    
    def set_default_language(self, language: str):
        """è®¾ç½®é»˜è®¤è¯­è¨€"""
        self.base_params['language'] = language
    
    def generate(self, text: str, **kwargs) -> Optional[bytes]:
        """ç”ŸæˆéŸ³é¢‘"""
        params = {**self.base_params, **kwargs, 'input': text}
        
        try:
            response = requests.post(
                f'{self.api_url}/v1/audio/speech',
                json=params,
                timeout=60
            )
            
            if response.status_code == 200:
                logger.info(f"âœ“ ç”ŸæˆæˆåŠŸ: {len(response.content)} å­—èŠ‚")
                return response.content
            else:
                logger.error(f"âœ— API é”™è¯¯ {response.status_code}: {response.text}")
                return None
        
        except requests.RequestException as e:
            logger.error(f"âœ— è¯·æ±‚å¤±è´¥: {e}")
            return None
    
    def save(self, text: str, filename: str, **kwargs) -> bool:
        """ç”Ÿæˆå¹¶ä¿å­˜éŸ³é¢‘"""
        audio_data = self.generate(text, **kwargs)
        
        if audio_data:
            with open(filename, 'wb') as f:
                f.write(audio_data)
            logger.info(f"âœ“ æ–‡ä»¶ä¿å­˜: {filename}")
            return True
        else:
            logger.error(f"âœ— ç”Ÿæˆå¤±è´¥")
            return False
    
    def batch_generate(self, texts: Dict[str, str], output_dir: str = '.') -> Dict[str, bool]:
        """æ‰¹é‡ç”Ÿæˆ"""
        results = {}
        
        for name, text in texts.items():
            filename = os.path.join(output_dir, f'{name}.mp3')
            results[name] = self.save(text, filename)
        
        return results
    
    def get_models(self) -> Optional[list]:
        """è·å–å¯ç”¨æ¨¡å‹åˆ—è¡¨"""
        try:
            response = requests.get(f'{self.api_url}/v1/models')
            if response.status_code == 200:
                return response.json().get('models', [])
        except Exception as e:
            logger.error(f"âœ— è·å–æ¨¡å‹åˆ—è¡¨å¤±è´¥: {e}")
        return None

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    load_dotenv()
    
    client = NanoAITTSClient('http://localhost:5001')
    
    # ç”Ÿæˆå•ä¸ªéŸ³é¢‘
    client.save('ä½ å¥½ï¼Œè¿™æ˜¯ä¸€ä¸ªæµ‹è¯•ã€‚', 'test.mp3')
    
    # æ‰¹é‡ç”Ÿæˆ
    texts = {
        'greeting': 'ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ NanoAI TTSã€‚',
        'thanks': 'è°¢è°¢ä½ çš„ä½¿ç”¨ï¼',
        'goodbye': 'å†è§ï¼'
    }
    
    results = client.batch_generate(texts, output_dir='./output')
    print(results)
    
    # åˆ—å‡ºå¯ç”¨æ¨¡å‹
    models = client.get_models()
    if models:
        print(f"å¯ç”¨æ¨¡å‹æ•°: {len(models)}")
        for model in models[:3]:
            print(f"  - {model.get('name')}")
```

#### ä¾‹ 7ï¼šå¤„ç†é•¿æ–‡æœ¬

```python
import requests
import re

def split_text(text: str, max_length: int = 500) -> list:
    """æŒ‰å¥å·ã€æ„Ÿå¹å·ã€é—®å·åˆ†å‰²æ–‡æœ¬"""
    # æŒ‰ä¸­æ–‡å’Œè‹±æ–‡æ ‡ç‚¹ç¬¦å·åˆ†å‰²
    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ\.\!\?]+', text)
    
    chunks = []
    current_chunk = ""
    
    for sentence in sentences:
        if len(current_chunk) + len(sentence) < max_length:
            current_chunk += sentence
        else:
            if current_chunk:
                chunks.append(current_chunk)
            current_chunk = sentence
    
    if current_chunk:
        chunks.append(current_chunk)
    
    return chunks

def generate_long_text_audio(text: str, output_file: str):
    """ç”Ÿæˆé•¿æ–‡æœ¬éŸ³é¢‘"""
    
    chunks = split_text(text)
    print(f"æ–‡æœ¬å·²åˆ†ä¸º {len(chunks)} ä¸ªéƒ¨åˆ†")
    
    audio_files = []
    
    for i, chunk in enumerate(chunks, 1):
        print(f"ç”Ÿæˆç¬¬ {i}/{len(chunks)} éƒ¨åˆ†...")
        
        response = requests.post('http://localhost:5001/v1/audio/speech', json={
            'input': chunk,
            'model': 'DeepSeek',
        })
        
        if response.status_code == 200:
            chunk_file = f'chunk_{i:03d}.mp3'
            with open(chunk_file, 'wb') as f:
                f.write(response.content)
            audio_files.append(chunk_file)
        else:
            print(f"ç¬¬ {i} éƒ¨åˆ†ç”Ÿæˆå¤±è´¥")
    
    print(f"âœ“ æ‰€æœ‰éƒ¨åˆ†ç”Ÿæˆå®Œæˆï¼Œå…± {len(audio_files)} ä¸ªéŸ³é¢‘æ–‡ä»¶")
    print(f"å¯ä»¥ä½¿ç”¨ ffmpeg æ‹¼æ¥è¿™äº›æ–‡ä»¶ï¼š")
    print(f"ffmpeg -f concat -safe 0 -i filelist.txt -c copy {output_file}")

# ä½¿ç”¨ç¤ºä¾‹
if __name__ == '__main__':
    long_text = """
    è¿™æ˜¯ä¸€ä¸ªå¾ˆé•¿çš„æ–‡æœ¬ç¤ºä¾‹ã€‚
    ç¬¬ä¸€æ®µå†…å®¹...
    ç¬¬äºŒæ®µå†…å®¹...
    """
    
    generate_long_text_audio(long_text, 'output.mp3')
```

## ğŸŒ JavaScript é›†æˆ

### åŸºç¡€ç¤ºä¾‹

#### ä¾‹ 1ï¼šåœ¨ HTML ä¸­ä½¿ç”¨

```html
<!DOCTYPE html>
<html>
<head>
    <title>NanoAI TTS Demo</title>
    <style>
        body { font-family: Arial, sans-serif; max-width: 600px; margin: 50px auto; }
        textarea { width: 100%; height: 100px; }
        button { padding: 10px 20px; font-size: 16px; }
        audio { width: 100%; margin-top: 20px; }
    </style>
</head>
<body>
    <h1>NanoAI TTS</h1>
    
    <textarea id="textInput" placeholder="è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬...">ä½ å¥½ï¼Œæ¬¢è¿ä½¿ç”¨ NanoAI TTSã€‚</textarea>
    
    <div>
        <label>è¯­è¨€ï¼š</label>
        <select id="language">
            <option value="zh-CN">ç®€ä½“ä¸­æ–‡</option>
            <option value="en-US">English</option>
            <option value="ja-JP">æ—¥æœ¬èª</option>
        </select>
    </div>
    
    <div>
        <label>æ€§åˆ«ï¼š</label>
        <select id="gender">
            <option value="female">å¥³å£°</option>
            <option value="male">ç”·å£°</option>
        </select>
    </div>
    
    <button onclick="generateAudio()">ç”ŸæˆéŸ³é¢‘</button>
    
    <audio id="audioPlayer" controls></audio>
    
    <script>
        async function generateAudio() {
            const text = document.getElementById('textInput').value;
            const language = document.getElementById('language').value;
            const gender = document.getElementById('gender').value;
            
            if (!text) {
                alert('è¯·è¾“å…¥æ–‡æœ¬');
                return;
            }
            
            try {
                const response = await fetch('http://localhost:5001/v1/audio/speech', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({
                        input: text,
                        model: 'DeepSeek',
                        language: language,
                        gender: gender
                    })
                });
                
                if (response.ok) {
                    const audioBlob = await response.blob();
                    const audioUrl = URL.createObjectURL(audioBlob);
                    document.getElementById('audioPlayer').src = audioUrl;
                } else {
                    alert('ç”Ÿæˆå¤±è´¥: ' + response.statusText);
                }
            } catch (error) {
                alert('é”™è¯¯: ' + error.message);
            }
        }
    </script>
</body>
</html>
```

#### ä¾‹ 2ï¼šReact ç»„ä»¶

```jsx
import React, { useState } from 'react';

function TTSGenerator() {
    const [text, setText] = useState('ä½ å¥½ï¼Œä¸–ç•Œ');
    const [language, setLanguage] = useState('zh-CN');
    const [gender, setGender] = useState('female');
    const [loading, setLoading] = useState(false);
    const [audioUrl, setAudioUrl] = useState(null);
    
    const generateAudio = async () => {
        setLoading(true);
        
        try {
            const response = await fetch('http://localhost:5001/v1/audio/speech', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json'
                },
                body: JSON.stringify({
                    input: text,
                    model: 'DeepSeek',
                    language,
                    gender
                })
            });
            
            if (response.ok) {
                const audioBlob = await response.blob();
                const url = URL.createObjectURL(audioBlob);
                setAudioUrl(url);
            } else {
                alert('ç”Ÿæˆå¤±è´¥');
            }
        } catch (error) {
            alert('é”™è¯¯: ' + error.message);
        } finally {
            setLoading(false);
        }
    };
    
    return (
        <div>
            <h1>NanoAI TTS</h1>
            
            <textarea
                value={text}
                onChange={(e) => setText(e.target.value)}
                placeholder="è¾“å…¥è¦è½¬æ¢çš„æ–‡æœ¬..."
                rows="5"
                style={{width: '100%'}}
            />
            
            <div>
                <label>è¯­è¨€: </label>
                <select value={language} onChange={(e) => setLanguage(e.target.value)}>
                    <option value="zh-CN">ç®€ä½“ä¸­æ–‡</option>
                    <option value="en-US">English</option>
                    <option value="ja-JP">æ—¥æœ¬èª</option>
                </select>
            </div>
            
            <div>
                <label>æ€§åˆ«: </label>
                <select value={gender} onChange={(e) => setGender(e.target.value)}>
                    <option value="female">å¥³å£°</option>
                    <option value="male">ç”·å£°</option>
                </select>
            </div>
            
            <button onClick={generateAudio} disabled={loading}>
                {loading ? 'ç”Ÿæˆä¸­...' : 'ç”ŸæˆéŸ³é¢‘'}
            </button>
            
            {audioUrl && (
                <audio controls src={audioUrl} style={{display: 'block', marginTop: '20px'}} />
            )}
        </div>
    );
}

export default TTSGenerator;
```

## ğŸ¬ å®æˆ˜åœºæ™¯

### åœºæ™¯ 1ï¼šåˆ¶ä½œè§†é¢‘é…éŸ³

**ç›®æ ‡**: ä¸ºæ•™å­¦è§†é¢‘æ·»åŠ ä¸­æ–‡é…éŸ³

```python
import requests
import json

def generate_video_voiceover(scenes_data):
    """
    scenes_data æ ¼å¼ï¼š
    [
        {'time': '0:00-0:10', 'text': 'è¿™æ˜¯ç¬¬ä¸€ä¸ªåœºæ™¯...'},
        {'time': '0:10-0:20', 'text': 'è¿™æ˜¯ç¬¬äºŒä¸ªåœºæ™¯...'},
    ]
    """
    
    output = {
        'voiceovers': []
    }
    
    for scene in scenes_data:
        response = requests.post('http://localhost:5001/v1/audio/speech', json={
            'input': scene['text'],
            'model': 'DeepSeek',
            'language': 'zh-CN',
            'gender': 'female',
            'speed': 1.0
        })
        
        if response.status_code == 200:
            # ä¿å­˜éŸ³é¢‘
            audio_file = f"voiceover_{len(output['voiceovers'])}.mp3"
            with open(audio_file, 'wb') as f:
                f.write(response.content)
            
            output['voiceovers'].append({
                'time': scene['time'],
                'text': scene['text'],
                'audio_file': audio_file
            })
    
    # ä¿å­˜é…ç½®
    with open('voiceover_config.json', 'w') as f:
        json.dump(output, f, ensure_ascii=False, indent=2)
    
    print(f"âœ“ ç”Ÿæˆäº† {len(output['voiceovers'])} ä¸ªé…éŸ³ç‰‡æ®µ")

# ä½¿ç”¨ç¤ºä¾‹
scenes = [
    {'time': '0:00-0:05', 'text': 'æ¬¢è¿æ¥åˆ°ä»Šå¤©çš„è¯¾ç¨‹'},
    {'time': '0:05-0:15', 'text': 'ä»Šå¤©æˆ‘ä»¬å°†å­¦ä¹ æœºå™¨å­¦ä¹ çš„åŸºç¡€çŸ¥è¯†'},
]

generate_video_voiceover(scenes)
```

### åœºæ™¯ 2ï¼šç”Ÿæˆæœ‰å£°ç”µå­ä¹¦

```python
import requests
import os

class AudiobookGenerator:
    def __init__(self, api_url='http://localhost:5001'):
        self.api_url = api_url
    
    def generate_from_file(self, input_file, output_dir='audiobook'):
        """ä»æ–‡æœ¬æ–‡ä»¶ç”Ÿæˆæœ‰å£°ä¹¦"""
        
        os.makedirs(output_dir, exist_ok=True)
        
        with open(input_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # åˆ†ç« èŠ‚
        chapters = content.split('## ')
        
        playlist = []
        
        for i, chapter in enumerate(chapters[1:], 1):  # è·³è¿‡ç¬¬ä¸€ä¸ªç©ºç« èŠ‚
            # æå–ç« èŠ‚æ ‡é¢˜
            lines = chapter.split('\n')
            title = lines[0] if lines else f'Chapter {i}'
            chapter_text = '\n'.join(lines[1:])
            
            print(f"æ­£åœ¨ç”Ÿæˆç¬¬ {i} ç« : {title}")
            
            response = requests.post(f'{self.api_url}/v1/audio/speech', json={
                'input': chapter_text,
                'model': 'DeepSeek',
                'language': 'zh-CN',
            })
            
            if response.status_code == 200:
                filename = f'chapter_{i:02d}.mp3'
                filepath = os.path.join(output_dir, filename)
                
                with open(filepath, 'wb') as f:
                    f.write(response.content)
                
                playlist.append({
                    'chapter': i,
                    'title': title,
                    'file': filename,
                    'size': len(response.content)
                })
                
                print(f"âœ“ ç¬¬ {i} ç« ç”Ÿæˆå®Œæ¯•")
            else:
                print(f"âœ— ç¬¬ {i} ç« ç”Ÿæˆå¤±è´¥")
        
        # ç”Ÿæˆæ’­æ”¾åˆ—è¡¨ï¼ˆM3U æ ¼å¼ï¼‰
        self._generate_m3u(output_dir, playlist)
        
        return playlist
    
    def _generate_m3u(self, output_dir, playlist):
        """ç”Ÿæˆ M3U æ’­æ”¾åˆ—è¡¨"""
        m3u_file = os.path.join(output_dir, 'playlist.m3u')
        
        with open(m3u_file, 'w', encoding='utf-8') as f:
            f.write('#EXTM3U\n')
            for item in playlist:
                f.write(f'#EXTINF:-1,{item["title"]}\n')
                f.write(f'{item["file"]}\n')
        
        print(f"âœ“ æ’­æ”¾åˆ—è¡¨ç”Ÿæˆ: {m3u_file}")

# ä½¿ç”¨ç¤ºä¾‹
generator = AudiobookGenerator()
playlist = generator.generate_from_file('novel.txt', output_dir='./audiobook')
```

### åœºæ™¯ 3ï¼šå­¦ä¹ åŠ©æ‰‹åº”ç”¨

```python
import requests

class LearningAssistant:
    """å­¦ä¹ åŠ©æ‰‹ - å¸®åŠ©å­¦ç”Ÿå­¦ä¹ è¯¾ç¨‹å†…å®¹"""
    
    def __init__(self, api_url='http://localhost:5001'):
        self.api_url = api_url
    
    def explain_concept(self, concept_name: str, explanation: str):
        """ç”¨è¯­éŸ³è§£é‡Šä¸€ä¸ªæ¦‚å¿µ"""
        
        text = f"{concept_name}ã€‚{explanation}"
        
        response = requests.post(f'{self.api_url}/v1/audio/speech', json={
            'input': text,
            'model': 'DeepSeek',
            'language': 'zh-CN',
            'gender': 'female',
            'speed': 0.9,  # ç¨å¾®æ”¾æ…¢é€Ÿåº¦ä¾¿äºç†è§£
        })
        
        if response.status_code == 200:
            return response.content
        return None
    
    def generate_vocabulary_lesson(self, words: list):
        """ç”Ÿæˆè¯æ±‡è¯¾ç¨‹"""
        
        lesson_files = {}
        
        for word_data in words:
            word = word_data['word']
            definition = word_data['definition']
            example = word_data.get('example', '')
            
            # ç”Ÿæˆè¯æ±‡éŸ³é¢‘
            word_audio = self.explain_concept(word, definition)
            
            # ç”Ÿæˆä¾‹å¥éŸ³é¢‘
            if example:
                example_audio = self.explain_concept('ä¾‹å¥', example)
            
            lesson_files[word] = {
                'definition': word_audio,
                'example': example_audio if example else None
            }
        
        return lesson_files
    
    def generate_listening_practice(self, sentences: list):
        """ç”Ÿæˆå¬åŠ›ç»ƒä¹ """
        
        audio_files = []
        
        for i, sentence in enumerate(sentences, 1):
            response = requests.post(f'{self.api_url}/v1/audio/speech', json={
                'input': sentence,
                'model': 'DeepSeek',
                'language': 'zh-CN',
            })
            
            if response.status_code == 200:
                filename = f'practice_{i}.mp3'
                with open(filename, 'wb') as f:
                    f.write(response.content)
                audio_files.append(filename)
        
        return audio_files

# ä½¿ç”¨ç¤ºä¾‹
assistant = LearningAssistant()

# è¯æ±‡å­¦ä¹ 
words = [
    {
        'word': 'ä¾¿æ·',
        'definition': 'æ–¹ä¾¿å¿«é€Ÿï¼Œä¸å¤æ‚',
        'example': 'è¿™ä¸ªæ–°çš„åº”ç”¨ç¨‹åºä½¿æ“ä½œå˜å¾—éå¸¸ä¾¿æ·ã€‚'
    },
    {
        'word': 'é˜è¿°',
        'definition': 'è¯¦ç»†è¯´æ˜ï¼Œæ¸…æ¥šåœ°è®²è§£',
        'example': 'æ•™æˆåœ¨è¯¾å ‚ä¸Šé˜è¿°äº†ç›¸å¯¹è®ºçš„åŸºæœ¬åŸç†ã€‚'
    }
]

vocab_lesson = assistant.generate_vocabulary_lesson(words)
```

## ğŸ“¦ æ‰¹é‡å¤„ç†

### æ‰¹é‡ç”Ÿæˆ CSV æ•°æ®

```python
import csv
import requests
import os

def batch_process_csv(csv_file, output_dir='output'):
    """
    CSV æ ¼å¼ï¼š
    text,language,gender,speed
    ä½ å¥½,zh-CN,female,1.0
    Hello,en-US,male,1.0
    """
    
    os.makedirs(output_dir, exist_ok=True)
    
    with open(csv_file, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for i, row in enumerate(reader, 1):
            text = row['text']
            language = row.get('language', 'zh-CN')
            gender = row.get('gender', 'female')
            speed = float(row.get('speed', 1.0))
            
            print(f"å¤„ç†ç¬¬ {i} è¡Œ: {text[:30]}...")
            
            response = requests.post('http://localhost:5001/v1/audio/speech', json={
                'input': text,
                'language': language,
                'gender': gender,
                'speed': speed,
            })
            
            if response.status_code == 200:
                filename = os.path.join(output_dir, f'audio_{i:04d}.mp3')
                with open(filename, 'wb') as f:
                    f.write(response.content)
                print(f"âœ“ å·²ä¿å­˜: {filename}")
            else:
                print(f"âœ— å¤±è´¥: {response.status_code}")

# ä½¿ç”¨
batch_process_csv('input.csv', output_dir='./audio_output')
```

## ğŸ¯ é«˜çº§æŠ€å·§

### 1. ç¼“å­˜ä¼˜åŒ–

åˆ©ç”¨ç¼“å­˜æé«˜é€Ÿåº¦ï¼š

```python
import requests
import hashlib

def get_audio_with_cache(text: str, cache_dir='cache'):
    """å¸¦ç¼“å­˜çš„éŸ³é¢‘ç”Ÿæˆ"""
    
    import os
    os.makedirs(cache_dir, exist_ok=True)
    
    # è®¡ç®—æ–‡æœ¬å“ˆå¸Œä½œä¸ºç¼“å­˜é”®
    text_hash = hashlib.md5(text.encode()).hexdigest()
    cache_file = os.path.join(cache_dir, f'{text_hash}.mp3')
    
    # æ£€æŸ¥ç¼“å­˜
    if os.path.exists(cache_file):
        print(f"âœ“ ä½¿ç”¨ç¼“å­˜")
        with open(cache_file, 'rb') as f:
            return f.read()
    
    # å¦‚æœæ²¡æœ‰ç¼“å­˜ï¼Œç”Ÿæˆæ–°çš„
    response = requests.post('http://localhost:5001/v1/audio/speech', json={
        'input': text,
        'model': 'DeepSeek',
    })
    
    if response.status_code == 200:
        # ä¿å­˜åˆ°ç¼“å­˜
        with open(cache_file, 'wb') as f:
            f.write(response.content)
        return response.content
    
    return None
```

### 2. æ€§èƒ½ç›‘æµ‹

```python
import requests
import time

def generate_with_timing(text: str):
    """è®°å½•ç”Ÿæˆæ—¶é—´"""
    
    start = time.time()
    
    response = requests.post('http://localhost:5001/v1/audio/speech', json={
        'input': text,
        'model': 'DeepSeek',
    })
    
    elapsed = time.time() - start
    
    if response.status_code == 200:
        size_kb = len(response.content) / 1024
        print(f"âœ“ ç”Ÿæˆè€—æ—¶: {elapsed:.2f}ç§’")
        print(f"âœ“ æ–‡ä»¶å¤§å°: {size_kb:.1f}KB")
        print(f"âœ“ é€Ÿç‡: {size_kb/elapsed:.1f}KB/s")
        
        return response.content
    
    return None
```

### 3. å¹¶å‘å¤„ç†

```python
import requests
import concurrent.futures

def generate_batch_concurrent(texts: list, max_workers=3):
    """å¹¶å‘ç”Ÿæˆå¤šä¸ªéŸ³é¢‘"""
    
    def generate_one(text):
        response = requests.post('http://localhost:5001/v1/audio/speech', json={
            'input': text,
            'model': 'DeepSeek',
        })
        return response.content if response.status_code == 200 else None
    
    results = []
    
    with concurrent.futures.ThreadPoolExecutor(max_workers=max_workers) as executor:
        futures = {executor.submit(generate_one, text): text for text in texts}
        
        for future in concurrent.futures.as_completed(futures):
            text = futures[future]
            try:
                result = future.result()
                if result:
                    results.append({'text': text, 'audio': result})
            except Exception as e:
                print(f"âœ— ç”Ÿæˆå¤±è´¥: {e}")
    
    return results
```

---

**æœ€åæ›´æ–°**: 2025å¹´12æœˆ15æ—¥  
**ç‰ˆæœ¬**: 1.0  
**éš¾åº¦ç­‰çº§**: åˆçº§ ~ é«˜çº§
